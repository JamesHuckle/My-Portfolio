{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import gym\n",
    "from gym import wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer():\n",
    "    def __init__(self, max_size, n_states):\n",
    "        self.mem_size = max_size # replay buffer size, max number of experiences to store\n",
    "        self.mem_cntr = 0  # replay buffer counter (used for indexing later)\n",
    "        self.state_memory = np.zeros((self.mem_size, n_states), dtype=np.float32)\n",
    "        self.new_state_memory = np.zeros((self.mem_size, n_states), dtype=np.float32)\n",
    "        self.action_memory = np.zeros(self.mem_size, dtype=np.int32)\n",
    "        self.reward_memory = np.zeros(self.mem_size, dtype=np.float32)\n",
    "        self.terminal_memory = np.zeros(self.mem_size, dtype=np.int32)\n",
    "\n",
    "    def store_transition(self, state, action, reward, state_, done):\n",
    "        index = self.mem_cntr % self.mem_size # When memory counter goes past max replay size, indexes at start of array\n",
    "        self.state_memory[index] = state\n",
    "        self.new_state_memory[index] = state_\n",
    "        self.reward_memory[index] = reward\n",
    "        self.action_memory[index] = action\n",
    "        self.terminal_memory[index] = done\n",
    "        self.mem_cntr += 1\n",
    "\n",
    "    def sample_buffer(self, batch_size):\n",
    "        max_mem = min(self.mem_cntr, self.mem_size) # number of experiences in replay buffer\n",
    "        batch = np.random.choice(max_mem, batch_size, replace=False) # select # experiences to train on\n",
    "\n",
    "        states = self.state_memory[batch]\n",
    "        states_ = self.new_state_memory[batch]\n",
    "        rewards = self.reward_memory[batch]\n",
    "        actions = self.action_memory[batch]\n",
    "        terminal = self.terminal_memory[batch]\n",
    "        return states, actions, rewards, states_, terminal\n",
    "\n",
    "class DQNAgent():\n",
    "    def __init__(self, env, lr, gamma, epsilon, batch_size, epsilon_dec=1e-3, epsilon_end=0.01, mem_size=1000000):\n",
    "        self.env = env\n",
    "        self.n_states = env.observation_space.shape[0]\n",
    "        self.n_actions = env.action_space.n\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.eps_dec = epsilon_dec\n",
    "        self.eps_min = epsilon_end\n",
    "        self.batch_size = batch_size\n",
    "        self.memory = ReplayBuffer(mem_size, self.n_states)\n",
    "        self.model = self.create_q_network(lr, fc1_dims=256, fc2_dims=256)\n",
    "        self.target_model = self.create_q_network(lr, fc1_dims=256, fc2_dims=256)\n",
    "        \n",
    "    def create_q_network(self, lr, fc1_dims, fc2_dims):\n",
    "        model = keras.Sequential([\n",
    "            keras.layers.Dense(fc1_dims, activation='relu', input_shape=(self.n_states,)),\n",
    "            keras.layers.Dense(fc2_dims, activation='relu'),\n",
    "            keras.layers.Dense(self.n_actions, activation=None)])\n",
    "        model.compile(optimizer=Adam(learning_rate=lr), loss='mean_squared_error')\n",
    "        return model\n",
    "\n",
    "    def set_new_lr(self, lr):\n",
    "        self.model.compile(optimizer=Adam(lr), loss='mean_squared_error')\n",
    "\n",
    "    def add_to_replay_buffer(self, state, action, reward, new_state, done):\n",
    "        self.memory.store_transition(state, action, reward, new_state, done)\n",
    "\n",
    "    def choose_action(self, observation):\n",
    "        if np.random.random() < self.epsilon:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            observation = np.expand_dims(observation, axis=0)\n",
    "            action = np.argmax(self.model.predict(observation))\n",
    "            \n",
    "        self.epsilon = max(self.eps_min, self.epsilon - self.eps_dec)\n",
    "        return action\n",
    "\n",
    "    def copy_across_model_weights(self):\n",
    "        if self.memory.mem_cntr % 100 == 0:\n",
    "            weights = self.model.get_weights()\n",
    "            self.target_model.set_weights(weights)\n",
    "    \n",
    "    def learn_from_replay_buffer(self):\n",
    "        if self.memory.mem_cntr < self.batch_size:\n",
    "            return\n",
    "        states, actions, rewards, next_states , dones = self.memory.sample_buffer(self.batch_size) \n",
    "        self.copy_across_model_weights()\n",
    "        q_state = self.model.predict(states)\n",
    "        q_next_state = self.target_model.predict(next_states)\n",
    "        q_state[range(len(q_state)), actions] = rewards + self.gamma * np.max(q_next_state, axis=1) * (1 - dones)\n",
    "       \n",
    "        self.model.train_on_batch(states, q_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# env_name = 'CartPole-v0' #DONE\n",
    "# env_name = 'MountainCar-v0' #DONE\n",
    "# env_name = 'MountainCarContinuous-v0'\n",
    "# env_name = 'Acrobot-v1' # DONE\n",
    "# env_name = 'Pendulum-v0' #DONE\n",
    "env_name = 'LunarLander-v2' #Done\n",
    "env = gym.make(env_name)\n",
    "\n",
    "lr = 0.0005\n",
    "agent = DQNAgent(env=env, gamma=0.99, epsilon=1.0, lr=lr, mem_size=1000000, batch_size=64, epsilon_dec=1e-4, epsilon_end=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0 score: -351.9 average_score: -352.0 epsilon: 0.99\n",
      "episode: 1 score: -76.41 average_score: -214.0 epsilon: 0.98\n",
      "episode: 2 score: -71.06 average_score: -166.0 epsilon: 0.97\n",
      "episode: 3 score: -120.98 average_score: -155.0 epsilon: 0.96\n",
      "episode: 4 score: -275.65 average_score: -179.0 epsilon: 0.95\n",
      "episode: 5 score: -254.03 average_score: -192.0 epsilon: 0.94\n",
      "episode: 6 score: -188.09 average_score: -191.0 epsilon: 0.93\n",
      "episode: 7 score: -45.34 average_score: -173.0 epsilon: 0.93\n",
      "episode: 8 score: -167.66 average_score: -172.0 epsilon: 0.92\n",
      "episode: 9 score: -87.12 average_score: -164.0 epsilon: 0.91\n",
      "episode: 10 score: -172.17 average_score: -165.0 epsilon: 0.89\n",
      "episode: 11 score: -96.27 average_score: -159.0 epsilon: 0.89\n",
      "episode: 12 score: -66.08 average_score: -152.0 epsilon: 0.88\n",
      "episode: 13 score: -80.29 average_score: -147.0 epsilon: 0.86\n",
      "episode: 14 score: -363.52 average_score: -161.0 epsilon: 0.85\n",
      "episode: 15 score: -111.17 average_score: -158.0 epsilon: 0.84\n",
      "episode: 16 score: -105.21 average_score: -155.0 epsilon: 0.84\n",
      "episode: 17 score: -94.2 average_score: -152.0 epsilon: 0.82\n",
      "episode: 18 score: -114.02 average_score: -150.0 epsilon: 0.82\n",
      "episode: 19 score: -55.39 average_score: -145.0 epsilon: 0.81\n",
      "episode: 20 score: -109.36 average_score: -143.0 epsilon: 0.79\n",
      "episode: 21 score: -255.51 average_score: -148.0 epsilon: 0.78\n",
      "episode: 22 score: -197.32 average_score: -150.0 epsilon: 0.77\n",
      "episode: 23 score: -169.74 average_score: -151.0 epsilon: 0.76\n",
      "episode: 24 score: -71.41 average_score: -148.0 epsilon: 0.75\n",
      "episode: 25 score: -26.79 average_score: -143.0 epsilon: 0.74\n",
      "episode: 26 score: 44.99 average_score: -136.0 epsilon: 0.73\n",
      "episode: 27 score: -70.67 average_score: -134.0 epsilon: 0.72\n",
      "episode: 28 score: -229.96 average_score: -137.0 epsilon: 0.71\n",
      "episode: 29 score: -121.17 average_score: -137.0 epsilon: 0.7\n",
      "episode: 30 score: -277.38 average_score: -141.0 epsilon: 0.69\n",
      "episode: 31 score: -215.34 average_score: -144.0 epsilon: 0.68\n",
      "episode: 32 score: -171.58 average_score: -144.0 epsilon: 0.67\n",
      "episode: 33 score: -19.41 average_score: -141.0 epsilon: 0.65\n",
      "episode: 34 score: -7.87 average_score: -137.0 epsilon: 0.64\n",
      "episode: 35 score: -97.82 average_score: -136.0 epsilon: 0.63\n",
      "episode: 36 score: -68.36 average_score: -134.0 epsilon: 0.63\n",
      "episode: 37 score: -47.02 average_score: -132.0 epsilon: 0.61\n",
      "episode: 38 score: -49.54 average_score: -130.0 epsilon: 0.61\n",
      "episode: 39 score: -88.64 average_score: -129.0 epsilon: 0.59\n",
      "episode: 40 score: -160.46 average_score: -129.0 epsilon: 0.59\n",
      "episode: 41 score: -23.41 average_score: -127.0 epsilon: 0.58\n",
      "episode: 42 score: -56.74 average_score: -125.0 epsilon: 0.57\n",
      "episode: 43 score: -78.02 average_score: -124.0 epsilon: 0.56\n",
      "episode: 44 score: -35.39 average_score: -122.0 epsilon: 0.55\n",
      "episode: 45 score: -44.44 average_score: -121.0 epsilon: 0.54\n",
      "episode: 46 score: -48.61 average_score: -119.0 epsilon: 0.53\n",
      "episode: 47 score: -53.73 average_score: -118.0 epsilon: 0.51\n",
      "episode: 48 score: -0.3 average_score: -115.0 epsilon: 0.51\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-a4e4a66e13ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m#reward += (abs(next_observation[0]) + 0.3)**2 / 100 # Mountain car exploration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_replay_buffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_observation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn_from_replay_buffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mobservation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext_observation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-64-8b46eb29fc72>\u001b[0m in \u001b[0;36mlearn_from_replay_buffer\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmem_cntr\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_states\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mdones\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_buffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_across_model_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mq_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-64-8b46eb29fc72>\u001b[0m in \u001b[0;36msample_buffer\u001b[1;34m(self, batch_size)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mstates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_memory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mstates_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_state_memory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mrewards\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreward_memory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mactions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_memory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "highscores = []\n",
    "epsilons = []\n",
    "\n",
    "n_games = 500\n",
    "for i in range(n_games):\n",
    "    done = False\n",
    "    score = 0\n",
    "    observation = env.reset()\n",
    "\n",
    "    while not done:       \n",
    "        action = agent.choose_action(observation)\n",
    "        next_observation, reward, done, info = env.step(action)\n",
    "        #reward += (abs(next_observation[0]) + 0.3)**2 / 100 # Mountain car exploration\n",
    "        agent.add_to_replay_buffer(observation, action, reward, next_observation, done)\n",
    "        agent.learn_from_replay_buffer()\n",
    "        observation = next_observation\n",
    "        score += reward\n",
    "        \n",
    "    epsilons.append(agent.epsilon)\n",
    "    highscores.append(score)\n",
    "\n",
    "    avg_score = np.mean(highscores[-100:])\n",
    "    print('episode:', i, 'score:', round(score, 2), 'average_score:', round(avg_score), 'epsilon:', round(agent.epsilon, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2c976178748>"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.Series(highscores).rolling(window=100, min_periods=1).mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[244.62071241214068]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_highscores = []\n",
    "\n",
    "for i in range(1):\n",
    "    done = False\n",
    "    score = 0\n",
    "    observation = env.reset()\n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = agent.choose_action(observation)\n",
    "        next_observation, reward, done, info = env.step(action)\n",
    "        observation = next_observation\n",
    "        score += reward\n",
    "        \n",
    "    test_highscores.append(score)\n",
    "    \n",
    "env.close()\n",
    "test_highscores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
