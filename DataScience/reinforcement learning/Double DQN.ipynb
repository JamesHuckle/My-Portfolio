{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import gym\n",
    "from gym import wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer():\n",
    "    def __init__(self, max_size, n_states):\n",
    "        self.mem_size = max_size # replay buffer size, max number of experiences to store\n",
    "        self.mem_cntr = 0  # replay buffer counter (used for indexing later)\n",
    "        self.state_memory = np.zeros((self.mem_size, n_states), dtype=np.float32)\n",
    "        self.new_state_memory = np.zeros((self.mem_size, n_states), dtype=np.float32)\n",
    "        self.action_memory = np.zeros(self.mem_size, dtype=np.int32)\n",
    "        self.reward_memory = np.zeros(self.mem_size, dtype=np.float32)\n",
    "        self.terminal_memory = np.zeros(self.mem_size, dtype=np.int32)\n",
    "\n",
    "    def store_transition(self, state, action, reward, state_, done):\n",
    "        index = self.mem_cntr % self.mem_size # When memory counter goes past max replay size, \n",
    "                                              # indexes at start of array\n",
    "        self.state_memory[index] = state\n",
    "        self.new_state_memory[index] = state_\n",
    "        self.reward_memory[index] = reward\n",
    "        self.action_memory[index] = action\n",
    "        self.terminal_memory[index] = done\n",
    "        self.mem_cntr += 1\n",
    "\n",
    "    def sample_buffer(self, batch_size):\n",
    "        max_mem = min(self.mem_cntr, self.mem_size) # number of experiences in replay buffer\n",
    "        batch = np.random.choice(max_mem, batch_size, replace=False) # select # experiences to \n",
    "                                                                     # train on\n",
    "        states = self.state_memory[batch]\n",
    "        states_ = self.new_state_memory[batch]\n",
    "        rewards = self.reward_memory[batch]\n",
    "        actions = self.action_memory[batch]\n",
    "        terminal = self.terminal_memory[batch]\n",
    "        return states, actions, rewards, states_, terminal\n",
    "\n",
    "class DDQNAgent():\n",
    "    def __init__(self, env, lr, gamma, epsilon, batch_size, epsilon_dec=1e-3, epsilon_end=0.01,\n",
    "                 mem_size=1000000):\n",
    "        self.env = env\n",
    "        self.n_states = env.observation_space.shape[0]\n",
    "        self.n_actions = env.action_space.n\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.eps_dec = epsilon_dec\n",
    "        self.eps_min = epsilon_end\n",
    "        self.batch_size = batch_size\n",
    "        self.memory = ReplayBuffer(mem_size, self.n_states)\n",
    "        self.model = self.create_q_network(lr, fc1_dims=256, fc2_dims=256)\n",
    "        self.target_model = self.create_q_network(lr, fc1_dims=256, fc2_dims=256)\n",
    "        \n",
    "    def create_q_network(self, lr, fc1_dims, fc2_dims):\n",
    "        model = keras.Sequential([\n",
    "            keras.layers.Dense(fc1_dims, activation='relu', input_shape=(self.n_states,)),\n",
    "            keras.layers.Dense(fc2_dims, activation='relu'),\n",
    "            keras.layers.Dense(self.n_actions, activation=None)])\n",
    "        model.compile(optimizer=Adam(learning_rate=lr), loss='mean_squared_error')\n",
    "        return model\n",
    "\n",
    "    def set_new_lr(self, lr):\n",
    "        self.model.compile(optimizer=Adam(lr), loss='mean_squared_error')\n",
    "\n",
    "    def add_to_replay_buffer(self, state, action, reward, new_state, done):\n",
    "        self.memory.store_transition(state, action, reward, new_state, done)\n",
    "\n",
    "    def choose_action(self, observation):\n",
    "        if np.random.random() < self.epsilon:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            observation = np.expand_dims(observation, axis=0)\n",
    "            action = np.argmax(self.model.predict(observation))\n",
    "            \n",
    "        self.epsilon = max(self.eps_min, self.epsilon - self.eps_dec)\n",
    "        return action\n",
    "\n",
    "    def copy_across_model_weights(self):\n",
    "        if self.memory.mem_cntr % 100 == 0:\n",
    "            weights = self.model.get_weights()\n",
    "            self.target_model.set_weights(weights)\n",
    "    \n",
    "    def learn_from_replay_buffer(self):\n",
    "        if self.memory.mem_cntr < self.batch_size:\n",
    "            return\n",
    "        states, actions, rewards, next_states , dones = self.memory.sample_buffer(self.batch_size) \n",
    "        q_states = self.model.predict(states)\n",
    "        q_next_states = self.target_model.predict(next_states)\n",
    "        \n",
    "        q_next_states_double = self.model.predict(next_states)\n",
    "        max_actions_double = np.argmax(q_next_states_double, axis=1)\n",
    "        \n",
    "        q_states[range(len(q_states)), actions] = (\n",
    "            rewards + self.gamma\n",
    "            #* np.max(q_next_states, axis=1) # DQN\n",
    "            * q_next_states[range(len(q_next_states)), max_actions_double] #DDQN\n",
    "            * (1 - dones)\n",
    "        )\n",
    "        \n",
    "        self.model.train_on_batch(states, q_states)\n",
    "        self.copy_across_model_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env_name = 'CartPole-v0' #DONE\n",
    "# env_name = 'MountainCar-v0' #DONE\n",
    "# env_name = 'MountainCarContinuous-v0'\n",
    "# env_name = 'Acrobot-v1' # DONE\n",
    "# env_name = 'Pendulum-v0' #DONE\n",
    "env_name = 'LunarLander-v2' #Done\n",
    "env = gym.make(env_name)\n",
    "\n",
    "lr = 0.0005\n",
    "agent = DDQNAgent(env=env, gamma=0.99, epsilon=1.0, lr=lr, mem_size=1000000, batch_size=64,\n",
    "                  epsilon_dec=1e-4, epsilon_end=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0 score: 32.0 average_score: 32 epsilon: 0.97\n",
      "episode: 1 score: 14.0 average_score: 23 epsilon: 0.95\n",
      "episode: 2 score: 20.0 average_score: 22 epsilon: 0.93\n",
      "episode: 3 score: 24.0 average_score: 22 epsilon: 0.91\n",
      "episode: 4 score: 19.0 average_score: 22 epsilon: 0.89\n",
      "episode: 5 score: 18.0 average_score: 21 epsilon: 0.87\n",
      "episode: 6 score: 13.0 average_score: 20 epsilon: 0.86\n",
      "episode: 7 score: 10.0 average_score: 19 epsilon: 0.85\n",
      "episode: 8 score: 15.0 average_score: 18 epsilon: 0.83\n",
      "episode: 9 score: 23.0 average_score: 19 epsilon: 0.81\n",
      "episode: 10 score: 22.0 average_score: 19 epsilon: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function ScopedTFGraph.__del__ at 0x0000029439CA4EE8>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jameshuckle\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\c_api_util.py\", line 54, in __del__\n",
      "    self.deleter(self.graph)\n",
      "AttributeError: 'ScopedTFGraph' object has no attribute 'deleter'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 11 score: 13.0 average_score: 19 epsilon: 0.78\n",
      "episode: 12 score: 30.0 average_score: 19 epsilon: 0.75\n",
      "episode: 13 score: 22.0 average_score: 20 epsilon: 0.72\n",
      "episode: 14 score: 17.0 average_score: 19 epsilon: 0.71\n",
      "episode: 15 score: 16.0 average_score: 19 epsilon: 0.69\n",
      "episode: 16 score: 10.0 average_score: 19 epsilon: 0.68\n",
      "episode: 17 score: 33.0 average_score: 20 epsilon: 0.65\n",
      "episode: 18 score: 15.0 average_score: 19 epsilon: 0.63\n",
      "episode: 19 score: 11.0 average_score: 19 epsilon: 0.62\n",
      "episode: 20 score: 11.0 average_score: 18 epsilon: 0.61\n",
      "episode: 21 score: 12.0 average_score: 18 epsilon: 0.6\n",
      "episode: 22 score: 15.0 average_score: 18 epsilon: 0.58\n",
      "episode: 23 score: 13.0 average_score: 18 epsilon: 0.57\n",
      "episode: 24 score: 19.0 average_score: 18 epsilon: 0.55\n",
      "episode: 25 score: 13.0 average_score: 18 epsilon: 0.54\n",
      "episode: 26 score: 11.0 average_score: 17 epsilon: 0.53\n",
      "episode: 27 score: 14.0 average_score: 17 epsilon: 0.51\n",
      "episode: 28 score: 23.0 average_score: 18 epsilon: 0.49\n",
      "episode: 29 score: 13.0 average_score: 17 epsilon: 0.48\n",
      "episode: 30 score: 11.0 average_score: 17 epsilon: 0.47\n",
      "episode: 31 score: 13.0 average_score: 17 epsilon: 0.45\n",
      "episode: 32 score: 11.0 average_score: 17 epsilon: 0.44\n",
      "episode: 33 score: 58.0 average_score: 18 epsilon: 0.39\n",
      "episode: 34 score: 16.0 average_score: 18 epsilon: 0.37\n",
      "episode: 35 score: 41.0 average_score: 19 epsilon: 0.33\n",
      "episode: 36 score: 14.0 average_score: 19 epsilon: 0.31\n",
      "episode: 37 score: 17.0 average_score: 18 epsilon: 0.3\n",
      "episode: 38 score: 104.0 average_score: 21 epsilon: 0.19\n",
      "episode: 39 score: 192.0 average_score: 25 epsilon: 0.0\n",
      "episode: 40 score: 62.0 average_score: 26 epsilon: 0\n",
      "episode: 41 score: 138.0 average_score: 29 epsilon: 0\n",
      "episode: 42 score: 61.0 average_score: 29 epsilon: 0\n",
      "episode: 43 score: 83.0 average_score: 30 epsilon: 0\n",
      "episode: 44 score: 63.0 average_score: 31 epsilon: 0\n",
      "episode: 45 score: 146.0 average_score: 34 epsilon: 0\n",
      "episode: 46 score: 189.0 average_score: 37 epsilon: 0\n",
      "episode: 47 score: 200.0 average_score: 40 epsilon: 0\n",
      "episode: 48 score: 200.0 average_score: 44 epsilon: 0\n",
      "episode: 49 score: 192.0 average_score: 47 epsilon: 0\n",
      "episode: 50 score: 96.0 average_score: 48 epsilon: 0\n",
      "episode: 51 score: 182.0 average_score: 50 epsilon: 0\n",
      "episode: 52 score: 126.0 average_score: 52 epsilon: 0\n",
      "episode: 53 score: 123.0 average_score: 53 epsilon: 0\n",
      "episode: 54 score: 200.0 average_score: 56 epsilon: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function IteratorResourceDeleter.__del__ at 0x000002943A9BE678>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jameshuckle\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\", line 538, in __del__\n",
      "    handle=self._handle, deleter=self._deleter)\n",
      "  File \"C:\\Users\\Jameshuckle\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\", line 1139, in delete_iterator\n",
      "    tld.op_callbacks, handle, deleter)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-0fc92e356759>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m#reward += (abs(next_observation[0]) + 0.3)**2 / 100 # Mountain car exploration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_replay_buffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_observation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn_from_replay_buffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mobservation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext_observation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-cb5a24d9995a>\u001b[0m in \u001b[0;36mlearn_from_replay_buffer\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mq_next_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[0mq_next_states_double\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m         \u001b[0mmax_actions_double\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq_next_states_double\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[0;32m     87\u001b[0m           method.__name__))\n\u001b[1;32m---> 88\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1247\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1248\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1249\u001b[1;33m           model=self)\n\u001b[0m\u001b[0;32m   1250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1251\u001b[0m       \u001b[1;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model)\u001b[0m\n\u001b[0;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1112\u001b[1;33m         model=model)\n\u001b[0m\u001b[0;32m   1113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m     \u001b[0mindices_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDatasetV2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"batch\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m       \u001b[0mindices_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpermutation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mrepeat\u001b[1;34m(self, count)\u001b[0m\n\u001b[0;32m   1103\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m     \"\"\"\n\u001b[1;32m-> 1105\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mRepeatDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, count)\u001b[0m\n\u001b[0;32m   3412\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3413\u001b[0m         \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3414\u001b[1;33m         **self._flat_structure)\n\u001b[0m\u001b[0;32m   3415\u001b[0m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRepeatDataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariant_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36mrepeat_dataset\u001b[1;34m(input_dataset, count, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   5235\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"RepeatDataset\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5236\u001b[0m         \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"output_types\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5237\u001b[1;33m         \"output_shapes\", output_shapes)\n\u001b[0m\u001b[0;32m   5238\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5239\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "highscores = []\n",
    "epsilons = []\n",
    "\n",
    "n_games = 500\n",
    "for i in range(n_games):\n",
    "    done = False\n",
    "    score = 0\n",
    "    observation = env.reset()\n",
    "\n",
    "    while not done:\n",
    "        action = agent.choose_action(observation)\n",
    "        next_observation, reward, done, info = env.step(action)\n",
    "        #reward += (abs(next_observation[0]) + 0.3)**2 / 100 # Mountain car exploration\n",
    "        agent.add_to_replay_buffer(observation, action, reward, next_observation, done)\n",
    "        agent.learn_from_replay_buffer()\n",
    "        observation = next_observation\n",
    "        score += reward\n",
    "        \n",
    "    epsilons.append(agent.epsilon)\n",
    "    highscores.append(score)\n",
    "\n",
    "    avg_score = np.mean(highscores[-100:])\n",
    "    print('episode:', i, 'score:', round(score, 2), 'average_score:',\n",
    "          round(avg_score), 'epsilon:', round(agent.epsilon, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2944042e4c8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.Series(highscores).rolling(window=100, min_periods=1).mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_highscores = []\n",
    "\n",
    "for i in range(1):\n",
    "    done = False\n",
    "    score = 0\n",
    "    observation = env.reset()\n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = agent.choose_action(observation)\n",
    "        next_observation, reward, done, info = env.step(action)\n",
    "        observation = next_observation\n",
    "        score += reward\n",
    "        \n",
    "    test_highscores.append(score)\n",
    "    \n",
    "env.close()\n",
    "test_highscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
