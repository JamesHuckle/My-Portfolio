{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plot\n",
    "import pandas as pd\n",
    "import time\n",
    "import gym\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear function approximator and episodic environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, env, alpha, gamma):\n",
    "        self.env = env\n",
    "        self.n_states = env.observation_space.shape[0]\n",
    "        self.n_actions = env.action_space.n\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.theta = self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        theta = np.random.random((self.n_actions, self.n_states))\n",
    "        return theta\n",
    "        \n",
    "    def choose_action(self, state):\n",
    "        action_pref = self.theta @ state.T   \n",
    "        exp_ = np.exp(action_pref)\n",
    "        softmax = exp_ / np.sum(exp_)\n",
    "        action = np.random.choice(range(self.n_actions), p=softmax)\n",
    "        return action, softmax  \n",
    "        \n",
    "    def softmax_grad(self, softmax):\n",
    "        s = softmax.reshape(-1, 1)\n",
    "        return np.diagflat(s) - s @ s.T\n",
    "\n",
    "    def weights_grad(self, probs, action, state):\n",
    "        policy_grad = self.softmax_grad(probs)[action]\n",
    "        policy_grad_norm = policy_grad / probs[action]\n",
    "        grad = state[None, :].T @ policy_grad_norm[None, :]\n",
    "        return grad.T\n",
    "    \n",
    "    #### Non-Vectorised equivilent to weights_grad ######\n",
    "    def weights_grad_(self, probs, action, state):\n",
    "        grad = np.zeros(self.theta.shape)\n",
    "        for a in range(self.n_actions):\n",
    "            if a == action:\n",
    "                grad[a, :] = state * (1 - probs[a])\n",
    "            else:\n",
    "                grad[a, :] = state * -probs[a]\n",
    "        return grad\n",
    "    \n",
    "    def update_weights(self, grads, rewards):\n",
    "        for idx, grad in enumerate(grads):\n",
    "            discounted_total_reward = sum([(self.gamma**step) * reward \n",
    "                                 for step, reward in enumerate(rewards[idx:])])\n",
    "            self.theta += self.alpha * discounted_total_reward * grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network (with normalized total rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNNAgent():\n",
    "    def __init__(self, env, alpha, gamma):\n",
    "        self.env = env\n",
    "        self.n_states = env.observation_space.shape[0]\n",
    "        self.n_actions = env.action_space.n\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.policy_model, self.predict_model = self.build_policy_network()\n",
    "        \n",
    "    def build_policy_network(self):\n",
    "        inputs = Input(shape=(self.n_states,))\n",
    "        rewards = Input(shape=[1])\n",
    "        dense1 = Dense(16, activation='relu')(inputs)\n",
    "        dense2 = Dense(16, activation='relu')(dense1)\n",
    "        probs = Dense(self.n_actions, activation='softmax')(dense2)\n",
    "\n",
    "        #negative log likelihood\n",
    "        def custom_loss(y_true, y_pred): #y_pred is softmax output, y_true is one hot of action taken\n",
    "            out = K.clip(y_pred, 1e-8, 1-1e-8)\n",
    "            log_lik = y_true * K.log(out)\n",
    "            return K.sum(-log_lik * rewards)\n",
    "        \n",
    "        policy_model = Model(inputs=[inputs, rewards], outputs=[probs])\n",
    "        policy_model.compile(optimizer=Adam(lr=self.alpha), loss=custom_loss)\n",
    "        \n",
    "        # predict model shares weights with policy model but is used with raw input (no rewards)\n",
    "        # to get a sofmax (predict) output\n",
    "        # It doesn't use the custom_loss function because we do not perform backprop and change weights\n",
    "        predict_model = Model(inputs=[inputs], outputs=[probs])\n",
    "        return policy_model, predict_model\n",
    "        \n",
    "    def choose_action(self, state):\n",
    "        softmax = self.predict_model.predict(state[None, :]).flatten()\n",
    "        action = np.random.choice(range(self.n_actions), p=softmax)\n",
    "        return action, softmax  \n",
    "        \n",
    "    def update_weights(self, states, rewards, actions):\n",
    "        total_rewards = []\n",
    "        for idx in range(len(rewards)):\n",
    "            discounted_total_reward = sum([(self.gamma**step) * reward \n",
    "                                 for step, reward in enumerate(rewards[idx:])])\n",
    "            total_rewards.append(discounted_total_reward)\n",
    "        total_rewards = (np.array(total_rewards) - np.mean(total_rewards)) / np.std(total_rewards)\n",
    "        total_rewards = np.vstack(total_rewards)\n",
    "        one_hot_actions = np.zeros((len(actions), self.n_actions))\n",
    "        one_hot_actions[range(len(actions)), actions] = 1\n",
    "        states = np.vstack(states)\n",
    "        self.policy_model.fit(x=[states, total_rewards], y=one_hot_actions, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = 'CartPole-v0'\n",
    "#env_name = 'LunarLander-v2' \n",
    "env = gym.make(env_name)\n",
    "\n",
    "gamma = 0.99\n",
    "alpha = 0.00005\n",
    "\n",
    "np.random.seed(1)\n",
    "agent = Agent(env, alpha, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highscores = [0]\n",
    "\n",
    "while np.mean(highscores[-100:]) < 195:\n",
    "#for episode in range(7500):\n",
    "    done = False\n",
    "    state = env.reset()\n",
    "    rewards = []\n",
    "    grads = []\n",
    "    score = 0\n",
    "    while not done:\n",
    "        #env.render() # pop up window showing agent\n",
    "        \n",
    "        action, probs = agent.choose_action(state)\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        grad = agent.weights_grad_(probs, action, state)\n",
    "        \n",
    "        rewards.append(reward)\n",
    "        grads.append(grad)\n",
    "        \n",
    "        state = next_state\n",
    "        score += reward\n",
    "        \n",
    "    agent.update_weights(grads, rewards)\n",
    "    \n",
    "    highscores.append(score)\n",
    "    print(f'episode: {episode} highscores: {np.mean(highscores[-100:])}', end=\"\\r\", flush=False)    \n",
    "        \n",
    "env.close() # closes popup window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = 'CartPole-v0'\n",
    "#env_name = 'LunarLander-v2' \n",
    "env = gym.make(env_name)\n",
    "\n",
    "gamma = 0.99\n",
    "alpha = 0.0005\n",
    "\n",
    "np.random.seed(1)\n",
    "agent = DNNAgent(env, alpha, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1426 highscores: 198.179292929294\r"
     ]
    }
   ],
   "source": [
    "highscores = [0]\n",
    "\n",
    "episode = -1\n",
    "while np.mean(highscores[-100:]) < 198:\n",
    "    episode += 1\n",
    "#for episode in range(7500):\n",
    "    done = False\n",
    "    state = env.reset()\n",
    "    states = []\n",
    "    rewards = []\n",
    "    actions = []\n",
    "    score = 0\n",
    "    while not done:\n",
    "        #env.render() # pop up window showing agent\n",
    "        \n",
    "        action, probs = agent.choose_action(state)\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        \n",
    "        states.append(state)\n",
    "        rewards.append(reward)\n",
    "        actions.append(action)\n",
    "        \n",
    "        state = next_state\n",
    "        score += reward\n",
    "        \n",
    "    agent.update_weights(states, rewards, actions)\n",
    "    \n",
    "    highscores.append(score)\n",
    "    print(f'episode: {episode} highscores: {np.mean(highscores[-100:])}', end=\"\\r\", flush=False)    \n",
    "        \n",
    "env.close() # closes popup window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x23816885dc8>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(highscores).rolling(window=100, min_periods=1).mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_highscores = []\n",
    "for episode in range(10):\n",
    "    done = False\n",
    "    state = env.reset()\n",
    "    score = 0\n",
    "    while not done:\n",
    "        env.render() # pop up window showing agent\n",
    "        \n",
    "        action, probs = agent.choose_action(state)\n",
    "        state, reward, done, info = env.step(action)\n",
    "        \n",
    "        score += reward\n",
    "    \n",
    "    test_highscores.append(score)\n",
    "    \n",
    "env.close()\n",
    "test_highscores "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
